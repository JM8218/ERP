import pandas as pd
import re
import logging

class MemberCSVIntegrator:
    def __init__(self):
        self.logger = self._setup_logger()
        
    def _setup_logger(self):
        logger = logging.getLogger('MemberIntegrator')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def load_csv_files(self, member_file, supporter_file):
        encodings = ['utf-8-sig', 'utf-8', 'cp949', 'euc-kr']
        
        def try_load_csv(file_path):
            for encoding in encodings:
                try:
                    df = pd.read_csv(file_path, encoding=encoding)
                    self.logger.info(f"{file_path} ë¡œë“œ ì„±ê³µ (ì¸ì½”ë”©: {encoding})")
                    return df
                except:
                    continue
            raise ValueError(f"{file_path} ë¡œë“œ ì‹¤íŒ¨")
        
        member_df = try_load_csv(member_file)
        supporter_df = try_load_csv(supporter_file)
        return member_df, supporter_df
    
    def normalize_phone(self, phone):
        if pd.isna(phone) or not phone:
            return None
        
        digits = re.sub(r'\D', '', str(phone))
        
        if len(digits) == 11 and digits.startswith('010'):
            return f"{digits[:3]}-{digits[3:7]}-{digits[7:]}"
        
        return str(phone).strip()
    
    def normalize_name(self, name):
        if pd.isna(name) or not name:
            return None
        
        name = re.sub(r'\s+', '', str(name).strip())
        return name if len(name) >= 2 else None
    
    def normalize_amount(self, amount):
        if pd.isna(amount) or not amount:
            return 0.0
        
        if isinstance(amount, str):
            amount = re.sub(r'[^\d.]', '', amount)
        
        try:
            return float(amount)
        except:
            return 0.0
    
    def standardize_dataframe(self, df, source_type):
        standardized = df.copy()
        
        # ì»¬ëŸ¼ëª… ë§¤í•‘
        column_mapping = {
            'ì´ë¦„': 'name', 'ì„±ëª…': 'name', 'íšŒì›ëª…': 'name', 'í›„ì›ìëª…': 'name',
            'ì „í™”ë²ˆí˜¸': 'phone', 'ì—°ë½ì²˜': 'phone', 'íœ´ëŒ€í°': 'phone',
            'ì´ë©”ì¼': 'email', 'ì´ë©”ì¼ì£¼ì†Œ': 'email', 'e-mail': 'email',
            'ì¡°í•©ë¹„': 'amount', 'í›„ì›ê¸ˆ': 'amount', 'ë‚©ì…ê¸ˆì•¡': 'amount', 'í›„ì›ê¸ˆì•¡': 'amount',
            'ì£¼ì†Œ': 'address', 'ê±°ì£¼ì§€': 'address',
            'ê°€ì…ì¼': 'join_date', 'ë“±ë¡ì¼': 'join_date', 'í›„ì›ì‹œì‘ì¼': 'join_date'
        }
        
        # ì»¬ëŸ¼ëª… ë³€ê²½
        for old_col, new_col in column_mapping.items():
            if old_col in standardized.columns:
                standardized = standardized.rename(columns={old_col: new_col})
        
        # í•„ìˆ˜ ì»¬ëŸ¼ ìƒì„±
        required_columns = ['name', 'phone', 'email', 'amount', 'address', 'join_date']
        for col in required_columns:
            if col not in standardized.columns:
                standardized[col] = None
        
        # ë°ì´í„° ì •ê·œí™”
        standardized['name'] = standardized['name'].apply(self.normalize_name)
        standardized['phone'] = standardized['phone'].apply(self.normalize_phone)
        standardized['amount'] = standardized['amount'].apply(self.normalize_amount)
        
        # ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€
        standardized['source_type'] = source_type
        
        # ìœ íš¨í•˜ì§€ ì•Šì€ í–‰ ì œê±°
        standardized = standardized.dropna(subset=['name'])
        standardized = standardized[standardized['name'].str.len() >= 2]
        
        return standardized
    
    def calculate_similarity(self, member1, member2):
        similarity_score = 0.0
        
        # ì´ë¦„ ìœ ì‚¬ë„
        if member1['name'] and member2['name']:
            if member1['name'] == member2['name']:
                similarity_score += 0.4
        
        # ì „í™”ë²ˆí˜¸ ìœ ì‚¬ë„
        if member1['phone'] and member2['phone']:
            if member1['phone'] == member2['phone']:
                similarity_score += 0.5
        
        # ì´ë©”ì¼ ìœ ì‚¬ë„
        if member1['email'] and member2['email']:
            if str(member1['email']).lower() == str(member2['email']).lower():
                similarity_score += 0.1
        
        return similarity_score
    
    def find_duplicates(self, df):
        duplicate_groups = []
        processed_indices = set()
        
        for i, row1 in df.iterrows():
            if i in processed_indices:
                continue
            
            duplicate_group = [i]
            
            for j, row2 in df.iterrows():
                if j <= i or j in processed_indices:
                    continue
                
                similarity = self.calculate_similarity(row1.to_dict(), row2.to_dict())
                
                if similarity >= 0.85:
                    duplicate_group.append(j)
                    processed_indices.add(j)
            
            if len(duplicate_group) > 1:
                duplicate_groups.append(duplicate_group)
                for idx in duplicate_group:
                    processed_indices.add(idx)
        
        return duplicate_groups
    
    def merge_duplicate_group(self, df, duplicate_indices):
        group_members = df.loc[duplicate_indices]
        
        # ì²« ë²ˆì§¸ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì„ íƒ
        primary_idx = duplicate_indices[0]
        primary = group_members.loc[primary_idx].to_dict()
        
        # ë³‘í•©ëœ ë ˆì½”ë“œ ìƒì„±
        merged = primary.copy()
        
        # íšŒì› íƒ€ì… ê²°ì •
        types = group_members['source_type'].unique()
        if len(types) > 1:
            merged['member_type'] = 'both'
        elif 'member' in types:
            merged['member_type'] = 'member'
        else:
            merged['member_type'] = 'supporter'
        
        # ë³‘í•© ì •ë³´ ì¶”ê°€
        merged['duplicate_flag'] = True
        merged['merged_count'] = len(duplicate_indices)
        
        return merged
    
    def integrate_members(self, member_file, supporter_file):
        self.logger.info("=== ì¡°í•©ì›/í›„ì›ì ëª…ë‹¨ í†µí•© ì‹œì‘ ===")
        
        # 1. íŒŒì¼ ë¡œë“œ
        member_df, supporter_df = self.load_csv_files(member_file, supporter_file)
        self.logger.info(f"ì¡°í•©ì›: {len(member_df)}í–‰, í›„ì›ì: {len(supporter_df)}í–‰")
        
        # 2. ë°ì´í„° í‘œì¤€í™”
        member_std = self.standardize_dataframe(member_df, 'member')
        supporter_std = self.standardize_dataframe(supporter_df, 'supporter')
        
        # 3. ë°ì´í„° í†µí•©
        combined_df = pd.concat([member_std, supporter_std], ignore_index=True)
        self.logger.info(f"í†µí•© ì „ ì´ {len(combined_df)}ê±´")
        
        # 4. ì¤‘ë³µ íƒì§€
        duplicate_groups = self.find_duplicates(combined_df)
        self.logger.info(f"ì¤‘ë³µ ê·¸ë£¹ {len(duplicate_groups)}ê°œ ë°œê²¬")
        
        # 5. ì¤‘ë³µ ë³‘í•©
        integrated_records = []
        processed_indices = set()
        
        # ì¤‘ë³µ ê·¸ë£¹ ë³‘í•©
        for group in duplicate_groups:
            merged_record = self.merge_duplicate_group(combined_df, group)
            integrated_records.append(merged_record)
            processed_indices.update(group)
        
        # ì¤‘ë³µë˜ì§€ ì•Šì€ ë ˆì½”ë“œ ì¶”ê°€
        for idx, row in combined_df.iterrows():
            if idx not in processed_indices:
                record = row.to_dict()
                record['member_type'] = record['source_type']
                record['duplicate_flag'] = False
                record['merged_count'] = 1
                integrated_records.append(record)
        
        result_df = pd.DataFrame(integrated_records)
        result_df = result_df.drop(['source_type'], axis=1, errors='ignore')
        result_df = result_df.reset_index(drop=True)
        
        self.logger.info(f"=== í†µí•© ì™„ë£Œ: {len(result_df)}ê±´ ===")
        return result_df
    
    def save_results(self, result_df, output_file='í†µí•©_ëª…ë‹¨.csv'):
        result_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        self.logger.info(f"í†µí•© ê²°ê³¼ ì €ì¥: {output_file}")
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = {
            'summary': {
                'total_members': len(result_df),
                'members_only': len(result_df[result_df['member_type'] == 'member']),
                'supporters_only': len(result_df[result_df['member_type'] == 'supporter']),
                'both': len(result_df[result_df['member_type'] == 'both']),
                'duplicates_merged': len(result_df[result_df['duplicate_flag'] == True])
            },
            'data_quality': {
                'complete_phone': len(result_df[result_df['phone'].notna()]),
                'complete_email': len(result_df[result_df['email'].notna()]),
                'has_amount': len(result_df[result_df['amount'] > 0])
            },
            'statistics': {
                'avg_amount': result_df['amount'].mean(),
                'total_amount': result_df['amount'].sum(),
                'max_amount': result_df['amount'].max(),
                'min_amount': result_df[result_df['amount'] > 0]['amount'].min() if len(result_df[result_df['amount'] > 0]) > 0 else 0
            }
        }
        
        return report

if __name__ == "__main__":
    integrator = MemberCSVIntegrator()
    
    try:
        result = integrator.integrate_members(
            member_file='utt/ì¡°í•©ì›_í›„ì›ìëª…ë¶€.csv',
            supporter_file='utt/í›„ì›ì_ëª…ë¶€.csv'
        )
        
        print(f"âœ… ê³ ê¸‰ ëª…ë¶€ í†µí•© ì™„ë£Œ: {len(result)}ëª…")
        print("\në¯¸ë¦¬ë³´ê¸°:")
        print(result[['name', 'phone', 'member_type', 'amount', 'duplicate_flag']].head())
        
        # ê²°ê³¼ ì €ì¥
        report = integrator.save_results(result, 'í†µí•©_ëª…ë‹¨.csv')
        
        print(f"\nğŸ“Š í†µí•© ê²°ê³¼:")
        print(f"- ì´ ì¸ì›: {report['summary']['total_members']}ëª…")
        print(f"- ì¡°í•©ì›ë§Œ: {report['summary']['members_only']}ëª…")
        print(f"- í›„ì›ìë§Œ: {report['summary']['supporters_only']}ëª…") 
        print(f"- ì¡°í•©ì›+í›„ì›ì: {report['summary']['both']}ëª…")
        print(f"- ì¤‘ë³µ ë³‘í•©: {report['summary']['duplicates_merged']}ê±´")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()